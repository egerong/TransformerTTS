{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Acoustic model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ.putenv(\"CUDA_VISIBLE_DEVICES\", \"-1\")\n",
    "config_path = \"config/peeter_koik.yaml\"\n",
    "outdir = \"./out\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-03 20:14:37.483692: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: could not check git hash. 'git_hash'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-03 20:14:38.438089: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcuda.so.1\n",
      "2022-02-03 20:14:38.595704: E tensorflow/stream_executor/cuda/cuda_driver.cc:328] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
      "2022-02-03 20:14:38.595732: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (kabinet): /proc/driver/nvidia/version does not exist\n",
      "2022-02-03 20:14:38.596348: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "restored weights from logs/peeter_koik_22/ljspeech/tts_config.aligner_config/weights/latest-311 at step 260000\n"
     ]
    }
   ],
   "source": [
    "from argparse import ArgumentParser\n",
    "from utils.config_manager import Config\n",
    "\n",
    "config_loader = Config(config_path=config_path)\n",
    "model = config_loader.load_model(None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"Katsetame uut lahendust t√§na.\"\n",
    "phons = model.text_pipeline.phonemizer(text)\n",
    "tokens = model.text_pipeline.tokenizer(phons)\n",
    "out = model.predict(tokens, encode=False, phoneme_max_duration=None)\n",
    "mel = out['mel'].numpy().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[WARNING] Unresolved object in checkpoint: (root).step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[WARNING] A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "2022-02-03 20:15:06.528181: W tensorflow/python/util/util.cc:348] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.\n",
      "[WARNING] Found untraced functions such as dropout_layer_call_and_return_conditional_losses, dropout_layer_call_fn, cnn_dropout_layer_call_and_return_conditional_losses, cnn_dropout_layer_call_fn, dense_20_layer_call_and_return_conditional_losses while saving (showing 5 of 960). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./out/model/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO] Assets written to: ./out/model/assets\n"
     ]
    }
   ],
   "source": [
    "model.build_model_weights()\n",
    "model.save(os.path.join(outdir, \"model\"), save_format='tf')\n",
    "#mel.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vocoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn.utils import weight_norm, remove_weight_norm\n",
    "from vocoding.predictors import HiFiGANPredictor\n",
    "\n",
    "vocoder = HiFiGANPredictor.from_folder('vocoding/hifigan/en').vocoder_model\n",
    "\n",
    "for m in vocoder.modules():\n",
    "    try:\n",
    "        m_tmp = remove_weight_norm(m)\n",
    "        m = m_tmp\n",
    "        #print(m)\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "_ = vocoder.eval()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from data.audio import Audio\n",
    "audio = Audio(config_loader.config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = mel[np.newaxis, :, :]\n",
    "t = torch.tensor(m)\n",
    "a = vocoder(t)\n",
    "a = a.squeeze()\n",
    "MAX_WAV_VALUE = 32768.0\n",
    "a = a * MAX_WAV_VALUE\n",
    "a = a.detach().numpy().astype('int16')\n",
    "audio.save_wav(a, os.path.join(outdir, \"audio.wav\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "script = torch.jit.script(vocoder)\n",
    "script.save(os.path.join(outdir, \"hifigan\"))\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "2b9994606e32cf4a85806f48a7c92b6ea0c3b6236220e216d69a238dbb4c7ba6"
  },
  "kernelspec": {
   "display_name": "Python 3.8.0 64-bit ('TransformerTTS': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
