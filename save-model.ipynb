{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Acoustic model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_path = \"config/peeter_koik.yaml\"\n",
    "outdir = \"./out\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'alphabet'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Input \u001b[0;32mIn [4]\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mconfig_manager\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Config\n\u001b[1;32m      5\u001b[0m config_loader \u001b[38;5;241m=\u001b[39m Config(config_path\u001b[38;5;241m=\u001b[39mconfig_path)\n\u001b[0;32m----> 6\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mconfig_loader\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      7\u001b[0m model\u001b[38;5;241m.\u001b[39msave(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(outdir, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n",
      "File \u001b[0;32m~/EKI/TransformerTTS/utils/config_manager.py:131\u001b[0m, in \u001b[0;36mConfig.load_model\u001b[0;34m(self, checkpoint_path, verbose)\u001b[0m\n\u001b[1;32m    130\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mload_model\u001b[39m(\u001b[38;5;28mself\u001b[39m, checkpoint_path: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[0;32m--> 131\u001b[0m     model \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    132\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcompile_model(model)\n\u001b[1;32m    133\u001b[0m     ckpt \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mtrain\u001b[38;5;241m.\u001b[39mCheckpoint(net\u001b[38;5;241m=\u001b[39mmodel)\n",
      "File \u001b[0;32m~/EKI/TransformerTTS/utils/config_manager.py:90\u001b[0m, in \u001b[0;36mConfig.get_model\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     88\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m Aligner\u001b[38;5;241m.\u001b[39mfrom_config(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig, max_r\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_r)\n\u001b[1;32m     89\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 90\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mForwardTransformer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_config\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/EKI/TransformerTTS/model/models.py:594\u001b[0m, in \u001b[0;36mForwardTransformer.from_config\u001b[0;34m(cls, config, custom_objects)\u001b[0m\n\u001b[1;32m    566\u001b[0m \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[1;32m    567\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfrom_config\u001b[39m(\u001b[38;5;28mcls\u001b[39m, config: \u001b[38;5;28mdict\u001b[39m, custom_objects\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    568\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mcls\u001b[39m(\n\u001b[1;32m    569\u001b[0m         encoder_model_dimension\u001b[38;5;241m=\u001b[39mconfig[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mencoder_model_dimension\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[1;32m    570\u001b[0m         decoder_model_dimension\u001b[38;5;241m=\u001b[39mconfig[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdecoder_model_dimension\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[1;32m    571\u001b[0m         dropout_rate\u001b[38;5;241m=\u001b[39mconfig[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdropout_rate\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[1;32m    572\u001b[0m         decoder_num_heads\u001b[38;5;241m=\u001b[39mconfig[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdecoder_num_heads\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[1;32m    573\u001b[0m         encoder_num_heads\u001b[38;5;241m=\u001b[39mconfig[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mencoder_num_heads\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[1;32m    574\u001b[0m         encoder_maximum_position_encoding\u001b[38;5;241m=\u001b[39mconfig[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mencoder_max_position_encoding\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[1;32m    575\u001b[0m         decoder_maximum_position_encoding\u001b[38;5;241m=\u001b[39mconfig[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdecoder_max_position_encoding\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[1;32m    576\u001b[0m         encoder_feed_forward_dimension\u001b[38;5;241m=\u001b[39mconfig[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mencoder_feed_forward_dimension\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[1;32m    577\u001b[0m         decoder_feed_forward_dimension\u001b[38;5;241m=\u001b[39mconfig[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdecoder_feed_forward_dimension\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[1;32m    578\u001b[0m         encoder_attention_conv_filters\u001b[38;5;241m=\u001b[39mconfig[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mencoder_attention_conv_filters\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[1;32m    579\u001b[0m         decoder_attention_conv_filters\u001b[38;5;241m=\u001b[39mconfig[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdecoder_attention_conv_filters\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[1;32m    580\u001b[0m         encoder_attention_conv_kernel\u001b[38;5;241m=\u001b[39mconfig[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mencoder_attention_conv_kernel\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[1;32m    581\u001b[0m         decoder_attention_conv_kernel\u001b[38;5;241m=\u001b[39mconfig[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdecoder_attention_conv_kernel\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[1;32m    582\u001b[0m         duration_conv_filters\u001b[38;5;241m=\u001b[39mconfig[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mduration_conv_filters\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[1;32m    583\u001b[0m         pitch_conv_filters\u001b[38;5;241m=\u001b[39mconfig[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpitch_conv_filters\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[1;32m    584\u001b[0m         duration_kernel_size\u001b[38;5;241m=\u001b[39mconfig[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mduration_kernel_size\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[1;32m    585\u001b[0m         pitch_kernel_size\u001b[38;5;241m=\u001b[39mconfig[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpitch_kernel_size\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[1;32m    586\u001b[0m         predictors_dropout\u001b[38;5;241m=\u001b[39mconfig[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpredictors_dropout\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[1;32m    587\u001b[0m         mel_channels\u001b[38;5;241m=\u001b[39mconfig[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmel_channels\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[1;32m    588\u001b[0m         encoder_dense_blocks\u001b[38;5;241m=\u001b[39mconfig[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mencoder_dense_blocks\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[1;32m    589\u001b[0m         decoder_dense_blocks\u001b[38;5;241m=\u001b[39mconfig[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdecoder_dense_blocks\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[1;32m    590\u001b[0m         phoneme_language\u001b[38;5;241m=\u001b[39mconfig[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mphoneme_language\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[1;32m    591\u001b[0m         with_stress\u001b[38;5;241m=\u001b[39mconfig[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwith_stress\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[1;32m    592\u001b[0m         debug\u001b[38;5;241m=\u001b[39mconfig[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdebug\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[1;32m    593\u001b[0m         model_breathing\u001b[38;5;241m=\u001b[39mconfig[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodel_breathing\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[0;32m--> 594\u001b[0m         alphabet\u001b[38;5;241m=\u001b[39m\u001b[43mconfig\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43malphabet\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'alphabet'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from argparse import ArgumentParser\n",
    "from utils.config_manager import Config\n",
    "\n",
    "config_loader = Config(config_path=config_path)\n",
    "model = config_loader.load_model()\n",
    "#model.save(os.path.join(outdir, \"model\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vocoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn.utils import weight_norm, remove_weight_norm\n",
    "from vocoding.predictors import HiFiGANPredictor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocoder = HiFiGANPredictor.from_folder('vocoding/hifigan/vctk')\n",
    "model = vocoder.vocoder_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove model weight norms, not needed for inference\n",
    "for m in model.modules():\n",
    "    try:\n",
    "        m_tmp = remove_weight_norm(m)\n",
    "        m = m_tmp\n",
    "        #print(m)\n",
    "    except:\n",
    "        pass\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "script = torch.jit.script(model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "script.save(\"hifigan.pt\")"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "2b9994606e32cf4a85806f48a7c92b6ea0c3b6236220e216d69a238dbb4c7ba6"
  },
  "kernelspec": {
   "display_name": "Python 3.8.0 64-bit ('TransformerTTS': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
